ifndef::imagesdir[:imagesdir: doc]
Zamia AI
========

The Zamia AI project provides all the components needed to build a free, open
source end-to-end natural language processing A.I. system. All components and
models used are free (as in speech), all the sources are open and freely
available not just for the software components but also all training data as
well as the tools needed to create the neural network models for the system.

This means you can build entirely self-contained A.I. systems with no dependencies
on proprietary components, data sources or cloud services that you do not control. 
Of course, you can always add or replace individual components by proprietary or cloud 
based ones if you wish but you can also take it to the other extreme and build 
completely self-contained systems that are capable of running in offline mode
with no network connectivity required at all. We like to call this concept
cloudless computing.

Typical systems that can be built based on Zamia AI include text based ones (i.e.
some sort of chat bot) and speech based ones (i.e. speech based assistants). 
Possible applications range from rather simple fun or educational toys up to
serious systems for command and control in industrial or automotive contexts
or assistive technology and healthcare solutions.

Architecture
------------

Right now the rough idea is to use a custom prolog system (AI-Prolog) at the core for knowledge storage, processing and
reasoning plus a seq2seq model to map natural language to prolog.

ifndef::env-github[]
[ditaa,"flow"]
....
  +-------------------+
  |  matural language |
  |                {d}|
  +-------------------+
            |
            v
  +-------------------+
  |     tokenizer     |
  +-------------------+
            |
            v
         tokens 
            |
            v
  +-------------------+
  |   seq2seq model   | 
  +-------------------+
            |
            v
       prolog code 
            |
            v
  +-------------------+
  | AI-Prolog engine  | 
  +-------------------+
            |
            |
            v
  +-------------------+
  |     response      |
  |                {d}|
  +-------------------+

....
endif::env-github[]
ifdef::env-github[]
image::flow.png[Dataflow]
endif::env-github[]

From a code organization perspective Zamia AI's architecture looks like this:

ifndef::env-github[]
[ditaa,"highlevel"]
....
+------------------------------------------------------------------------------------------------+
|                                         Applications                                           |
|                                                                                                |
+------------------------------------------------------------------------------------------------+
         ^                                      ^                                       |
         |                                      |                                       v
         |                            utterances/intents                           utterances
         |                                      ^                                       |
         |                                      |                                       v
         |            +--------------------------------------------------------------------------+
         |            |                         |  Zamia AI                             |        |
         |            |  +---------------+    +------------------+                      |        |
         |            |  |  Data-Tools   |    |     AI Prolog    |                      v        |
         |            |  |               |    |                  |                 +---------+   |
         |            |  | - LDF mirror  |    |      runtime     |<- prolog code --| seq2seq |   |
         |            |  | - AIML import |    |                  |<- inference -+  |  model  |   |
         |            |  | - chat import |    |                  |              |  +---------+   |
         |            |  +---------------+    |                  |              |       ^        |
         |            |         |             |                  |              |       |        |
         |            |         v             |                  |              |     train      |
         |            |  +---------------+    |                  |              |       ^        |
         |            |  |   Modules     |    |                  |              |       |        |
         |            |  |               |    |                  |              |  /----------\  |
         |            |  | - wikidata    |    |                  |              +->|          |  |
         |            |  | - base        |--->|     compiler     |--- clauses    ->| database |  |
         |            |  | - smalltalk   |    |    macro engine  |--- utterances ->|          |  |
         |            |  | - personality |    |                  |                 \----------/  |
         |            |  | - weather     |    +------------------+                               |
         |            |  |   ...         |                                                       |
         |            |  +---------------+                                                       |
         |            |                                                                          |
         |            +--------------------------------------------------------------------------+
         |                                               ^
         |                                               |
         v                                               v
 +-----------------------------------------------------------------------------------------------+
 |                                           nltools                                             |
 | +-----------+  +-----------+  +------------+                                                  |
 | | tokenizer |  | phonetics |  | threadpool |                                                  |
 | +-----------+  +-----------+  +------------+                                                  |
 |                                                                                               |
 |      +-----------+               +-----------+     +-----------+ +-----------+ +-----------+  |
 |      |    tts    |               |    asr    |     |    vad    | |    g2p    | |   audio   |  |
 |      +-----------+               +-----------+     +-----------+ +-----------+ +-----------+  |
 |            |                           |                 |             |             |        |
 +-----------------------------------------------------------------------------------------------+
              |                           |                 |             |             |          
     +--------+---------+          +------+----+            |             |             |
     |        |         |          |           |            |             |             |
     v        v         v          v           v            v             v             v
 +------+ +--------+ +------+  +-------+ +-----------+ +--------+    +----------+ +------------+ 
 | mary | | eSpeak | | pico |  | kaldi | | cmusphinx | | webrtc |    | sequitur | | pulseaudio |
 +------+ +--------+ +------+  +-------+ +-----------+ +--------+    +----------+ +------------+
....
endif::env-github[]
ifdef::env-github[]
image::highlevel.png[Highlevel Diagram]
endif::env-github[]

One of the key features of the current setup is the way training data is stored/generated.
I am using a modularized approach here (see the modules/ directory for humble beginnings of this)
where I store snippets of natural language which uses a macro system for somewhat rule-based
generation of language examples (optionally incorporating data from the prolog knowledge base) 
and prolog code to execute it.

Knowledge Base Notes
--------------------

NOTE: at the time of this writing the general architecture of this system is still in flux, therefore documentation will
probably be more or less outdated.

// For documentation on ZamiaAI semantic processing, see <<doc/semantics#,semantics>>.

=== Context Provided by Framework

Implicit argument `C` which is initialized to a unique prolog constant representing the
current round (i.e. interaction step). 

e.g. `C = context42`

assertions made by framework:

```prolog
user    (context42, userDefault).
lang    (context42, en).
tokens  (context42, ['hi', 'there']).
time    (context42, "2004-06-14T23:34:30").
prev    (context42, context41).
```

any assertions of the form

```prolog
context (context41, key, value).
mem     (context41, key, value).
```

made on the previous context will be made again (i.e.: persist) on the current context,
context assertions will also serve as additional inputs to subsequent neural net runs


=== Response

The response generated by prolog processing is comprised of assertions such as:

```prolog
c_say    (C, token).
c_action (C, [args]).
c_score  (C, score).
```

=== data-tools

==== RDF

RDF data can be mirrored and converted to AI-Prolog using the scripts found in `data-tools/rdf`.

Example: mirror the wikidata subset and generate AI-Prolog from it:

```bash
cd data-tools/rdf
edit config.py as needed

./ldfmirror.py -o rdf/wd_sub.n3
./rdf2prolog.py -o ../../modules/data/wd_sub.pl rdf/wd_sub.n3
cd ../..
./ai_cli.py compile data
```

==== AIML / Chat data

Data from AIML sources can be converted to `chat` format which can then be turned into AI-Prolog training scripts:

```bash
pushd data-tools/aiml
./chatterbots2chat.sh
popd
data-tools/chat/chat2aip.py -l en -o modules/chat/en.aip data-tools/aiml/bots_en/alice_new.chat data-tools/aiml/bots_en/square_bear.chat data-tools/aiml/bots_en/dobby.chat data-tools/aiml/bots_en/emmie.chat data-tools/aiml/bots_en/proalias.chat data-tools/aiml/bots_en/rosie.chat data-tools/aiml/bots_en/runabot.chat tmp/chat_corpus/movie_subtitles_en.txt 
data-tools/chat/chat2aip.py -t -l de -o modules/chat/de.aip data-tools/aiml/bots_de/alice.chat
```

module initialization / test setup
----------------------------------

when a aiprolog module is loaded for processing, a special target

```prolog
    init("module_name")
```

is searched for and actions produced from this search are executed. this mechanism can
be used to initialize the module through prolog code in general and setup default 
context values in particular, as 

```
    ai:curin  ai:user aiu:default
```

is set during execution.

Additionally, before running each test, a special target
```prolog
    test_setup("module_name")
```
is searched. 
```
    ai_curin  ai:user aiu:test
```
is set during execution

Links
-----

* Code: https://github.com/gooofy/zamia-ai

Requirements
------------

*Note*: probably incomplete.

* Python 2.7 with nltk, numpy, ...
* tensorflow
* from my other repositories: py-nltools, zamia-prolog

Setup Notes
-----------

Just some rough notes on the environment needed to get these scripts to run. This is in no way a complete set of
instructions, just some hints to get you started.

create a file called `~/.airc`:

```ini
[db]
url                 = sqlite:///ai.db

[semantics]
modules             = data, config, base, dialog, mathematics, dt, humans, weather, media, movies, television, literature, tech, geo, astro, culture, social, economy, physics, games, miscellaneous, music, mythology, transport, health, humor, psychology, politics, language, sports, food, news, history, legal, personal, home
server_host         = dagobert
server_port         = 8302

[weather]
api_key             = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
city_id             = 2825297
city_pred           = stuttgart

[context]
place               = 'http://www.wikidata.org/entity/Q1022'
channel             = 'http://www.wikidata.org/entity/Q795291'
time                = today
```

compile the knowledge base:
```bash
./ai_cli.py compile all
```
train a model:
```bash
./ai_cli.py train models/en_3_512.ini
```
alternatively, you can download a pre-built model here: http://goofy.zamia.org/zamia-ai/

chat with the model:
```bash
[guenter@dagobert zamia-ai]$ ./ai_cli.py chat models/en_3_512.ini 
[...]
INFO:root:models/en_3_512/in_dict.csv read, 3128 entries, output_max_len=21.
INFO:root:models/en_3_512/out_dict.csv read, 1811 entries, output_max_len=128.
INFO:root:creating decode seq2seq model: 3 layer(s) of 512 units.
INFO:root:building model..
INFO:root:building encoder..
INFO:root:building decoder and attention..
INFO:root:use beamsearch decoding..
INFO:root:building beamsearch decoder..
INFO:tensorflow:Restoring parameters from models/en_3_512/latest.ckpt
INFO:tensorflow:Restoring parameters from models/en_3_512/latest.ckpt
INFO:root:model restored from models/en_3_512/latest.ckpt
ai> hello computer
INFO:root:RESP: [00000] hello ! 
ai> how are you?
INFO:root:RESP: [00000] thanks for asking , i am doing fine . how about you ? 
ai> I am well
INFO:root:RESP: [00000] glad to hear that . 
ai> what is 2 times 2
INFO:root:RESP: [00100] 4 
ai> correct
INFO:root:RESP: [00000] good . 
ai> where do you live?
INFO:root:RESP: [00000] i am locted in Stuttgart . 
ai> what is your favorite movie?
INFO:root:RESP: [00000] 2001: A Space Odyssey by Stanley Kubrick 
ai> How about the weather?
INFO:root:RESP: [00000] always a good topic . 
ai> I thought so too.
INFO:root:RESP: [00000] so we are in agreement ? 
ai> Tell me something about yourself
INFO:root:RESP: [00000] my clock ticks more than a billion times a second . 
```

Language Model
--------------

dump sentences from training data for LM generation:

```bash
./ai_cli.py utterances 
```

or to dump out a set of 20 random utterances which contain words not covered by the dictionary:

```bash
./ai_cli.py utterances -d ../speech/data/src/speech/de/dict.ipa -n 20
```

License
-------

My own scripts as well as the data I create is LGPLv3 licensed unless otherwise noted in the script's copyright headers.

Some scripts and files are based on works of others, in those cases it is my
intention to keep the original license intact. Please make sure to check the
copyright headers inside for more information.

Author
------

Guenter Bartsch <guenter@zamia.org>

